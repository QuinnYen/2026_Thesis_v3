"""
å®Œæ•´å¯¦é©—æµç¨‹ä¸»æ§è…³æœ¬

è‡ªå‹•åŸ·è¡Œä»¥ä¸‹æ‰€æœ‰æ­¥é©Ÿï¼š
1. è³‡æ–™æ¸…ç†èˆ‡é©—è­‰
2. è¨“ç·´æ‰€æœ‰æ¨¡å‹ï¼ˆBaseline + Pre-Fusion + Post-Fusionï¼‰
3. ç”Ÿæˆæ¯”è¼ƒè¡¨æ ¼
4. ç”Ÿæˆé«˜å“è³ªåœ–è¡¨
5. ç”¢ç”Ÿå®Œæ•´å¯¦é©—å ±å‘Š

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/run_full_experiment.py

åƒæ•¸ï¼š
    --skip-cleaning     è·³éè³‡æ–™æ¸…ç†æ­¥é©Ÿ
    --skip-training     è·³éæ¨¡å‹è¨“ç·´æ­¥é©Ÿ
    --skip-analysis     è·³éåˆ†æèˆ‡è¦–è¦ºåŒ–æ­¥é©Ÿ
    --models            æŒ‡å®šè¦è¨“ç·´çš„æ¨¡å‹ï¼ˆé è¨­ï¼šallï¼‰
                       å¯é¸ï¼šbaseline, prefusion, postfusion, all
"""

import subprocess
import sys
import time
from pathlib import Path
import argparse
import json

# è¨­å®šå°ˆæ¡ˆæ ¹ç›®éŒ„
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(BASE_DIR / "configs"))

# å°å…¥é…ç½®
from experiment_config import DATASETS


def print_section(title):
    """å°å‡ºåˆ†éš”ç·šæ¨™é¡Œ"""
    print("\n" + "=" * 80)
    print(f"{title}")
    print("=" * 80 + "\n")


def run_command(description, command, timeout=3600):
    """
    åŸ·è¡Œç³»çµ±å‘½ä»¤ä¸¦å³æ™‚é¡¯ç¤ºè¼¸å‡º

    Args:
        description: å‘½ä»¤æè¿°
        command: è¦åŸ·è¡Œçš„å‘½ä»¤ï¼ˆå­—ä¸²æˆ–åˆ—è¡¨ï¼‰
        timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰

    Returns:
        bool: å‘½ä»¤æ˜¯å¦æˆåŠŸåŸ·è¡Œ
    """
    print(f"\n>>> {description}")
    print(f">>> åŸ·è¡Œå‘½ä»¤: {' '.join(command) if isinstance(command, list) else command}")
    print("-" * 80)

    start_time = time.time()

    try:
        # ä½¿ç”¨ subprocess.run ä¸¦å³æ™‚é¡¯ç¤ºè¼¸å‡º
        result = subprocess.run(
            command if isinstance(command, list) else command.split(),
            cwd=BASE_DIR,
            capture_output=False,  # ç›´æ¥é¡¯ç¤ºè¼¸å‡º
            text=True,
            timeout=timeout
        )

        elapsed_time = time.time() - start_time

        if result.returncode == 0:
            print(f"\n[æˆåŠŸ] {description} - è€—æ™‚ {elapsed_time:.1f} ç§’")
            return True
        else:
            print(f"\n[å¤±æ•—] {description} - è¿”å›ç¢¼ {result.returncode}")
            return False

    except subprocess.TimeoutExpired:
        print(f"\n[è¶…æ™‚] {description} - è¶…é {timeout} ç§’")
        return False
    except Exception as e:
        print(f"\n[éŒ¯èª¤] {description} - {str(e)}")
        return False


def step1_data_cleaning():
    """æ­¥é©Ÿ 1ï¼šè³‡æ–™æ¸…ç†èˆ‡é©—è­‰"""
    print_section("æ­¥é©Ÿ 1/4ï¼šè³‡æ–™æ¸…ç†èˆ‡é©—è­‰")

    # 1.1 æ¸…ç†è³‡æ–™
    success = run_command(
        "æ¸…ç† Aspect-Level è³‡æ–™ï¼ˆç§»é™¤è¡çªæ¨™ç±¤ï¼‰",
        ["python", "scripts/clean_aspect_data.py"],
        timeout=300
    )
    if not success:
        print("\n[è­¦å‘Š] è³‡æ–™æ¸…ç†å¤±æ•—ï¼Œä½†å°‡ç¹¼çºŒåŸ·è¡Œ")

    # 1.2 é©—è­‰æ¸…ç†çµæœ
    success = run_command(
        "é©—è­‰æ¸…ç†å¾Œè³‡æ–™å“è³ª",
        ["python", "scripts/verify_cleaning.py"],
        timeout=120
    )
    if not success:
        print("\n[è­¦å‘Š] è³‡æ–™é©—è­‰å¤±æ•—ï¼Œä½†å°‡ç¹¼çºŒåŸ·è¡Œ")

    return True


def step2_train_models(models='all'):
    """æ­¥é©Ÿ 2ï¼šè¨“ç·´æ‰€æœ‰æ¨¡å‹ï¼ˆåœ¨æ‰€æœ‰é…ç½®çš„æ•¸æ“šé›†ä¸Šï¼‰"""
    print_section("æ­¥é©Ÿ 2/4ï¼šæ¨¡å‹è¨“ç·´")

    print(f"å°‡åœ¨ä»¥ä¸‹ {len(DATASETS)} å€‹æ•¸æ“šé›†ä¸Šè¨“ç·´æ¨¡å‹:")
    for dataset in DATASETS:
        print(f"  - {dataset}")
    print()

    # ä½¿ç”¨ train_all_datasets.py è…³æœ¬
    success = run_command(
        f"åœ¨æ‰€æœ‰æ•¸æ“šé›†ä¸Šè¨“ç·´æ¨¡å‹ï¼ˆæ¨¡å‹é¡å‹: {models}ï¼‰",
        ["python", "scripts/train_all_datasets.py", "--model", models],
        timeout=14400  # 4 å°æ™‚
    )

    if not success:
        print("\n[éŒ¯èª¤] æ¨¡å‹è¨“ç·´å¤±æ•—")
        return False

    print("\n[æˆåŠŸ] æ‰€æœ‰æ¨¡å‹è¨“ç·´å®Œæˆ")
    return True


def step3_generate_analysis():
    """æ­¥é©Ÿ 3ï¼šç”Ÿæˆåˆ†æå ±å‘Šèˆ‡è¦–è¦ºåŒ–"""
    print_section("æ­¥é©Ÿ 3/4ï¼šçµæœåˆ†æèˆ‡è¦–è¦ºåŒ–")

    # 3.1 ç”Ÿæˆæ¯”è¼ƒè¡¨æ ¼
    print("\n--- ç”Ÿæˆæ¯”è¼ƒè¡¨æ ¼ ---")
    success = run_command(
        "ç”Ÿæˆè«–æ–‡æ¯”è¼ƒè¡¨æ ¼ï¼ˆTable 1-3ï¼‰",
        ["python", "scripts/generate_comparison_tables.py"],
        timeout=300
    )
    if not success:
        print("\n[éŒ¯èª¤] è¡¨æ ¼ç”Ÿæˆå¤±æ•—")
        return False

    # 3.2 ç”Ÿæˆé«˜å“è³ªåœ–è¡¨
    print("\n--- ç”Ÿæˆé«˜å“è³ªåœ–è¡¨ ---")
    success = run_command(
        "ç”Ÿæˆè«–æ–‡åœ–è¡¨ï¼ˆFigure 1-5ï¼Œ300 DPIï¼‰",
        ["python", "scripts/generate_figures.py"],
        timeout=300
    )
    if not success:
        print("\n[éŒ¯èª¤] åœ–è¡¨ç”Ÿæˆå¤±æ•—")
        return False

    return True


def step4_generate_report():
    """æ­¥é©Ÿ 4ï¼šç”¢ç”Ÿå®Œæ•´å¯¦é©—å ±å‘Šï¼ˆåŒ…å«æ‰€æœ‰æ•¸æ“šé›†ï¼‰"""
    print_section("æ­¥é©Ÿ 4/4ï¼šç”¢ç”Ÿå®Œæ•´å¯¦é©—å ±å‘Š")

    # ä½¿ç”¨ç¨ç«‹çš„å ±å‘Šç”Ÿæˆè…³æœ¬
    success = run_command(
        "ç”Ÿæˆå®Œæ•´å¯¦é©—å ±å‘Šï¼ˆåŒ…å«æ‰€æœ‰æ•¸æ“šé›†ï¼‰",
        ["python", "scripts/generate_report.py"],
        timeout=120
    )

    if not success:
        print("\n[éŒ¯èª¤] å ±å‘Šç”Ÿæˆå¤±æ•—")
        return False

    return True

def step4_generate_report_old():
    """æ­¥é©Ÿ 4ï¼šç”¢ç”Ÿå®Œæ•´å¯¦é©—å ±å‘Šï¼ˆåŒ…å«æ‰€æœ‰æ•¸æ“šé›†ï¼‰- èˆŠç‰ˆæœ¬"""
    print_section("æ­¥é©Ÿ 4/4ï¼šç”¢ç”Ÿå®Œæ•´å¯¦é©—å ±å‘Š")

    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("å®Œæ•´å¯¦é©—å ±å‘Š")
    report_lines.append("=" * 80)
    report_lines.append("")

    base_experiment_dir = BASE_DIR / "outputs" / "experiments" / "aspect_level_v2"

    # éæ­·æ‰€æœ‰æ•¸æ“šé›†
    for dataset_name in DATASETS:
        experiment_dir = base_experiment_dir / dataset_name

        if not experiment_dir.exists():
            report_lines.append(f"\nâš ï¸  {dataset_name}: ç„¡å¯¦é©—çµæœ")
            continue

        report_lines.append(f"\n{'=' * 80}")
        report_lines.append(f"æ•¸æ“šé›†: {dataset_name}")
        report_lines.append(f"{'=' * 80}")

        # æƒææ‰€æœ‰å¯¦é©—çµæœ
        models_found = []

        # Baseline
        baseline_path = experiment_dir / "baseline_cleaned" / "results" / "experiment_result.json"
        if baseline_path.exists():
            with open(baseline_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                models_found.append({
                    'name': 'Baseline',
                    'accuracy': data['final_metrics']['accuracy'],
                    'f1': data['final_metrics']['macro_f1'],
                    'params': data.get('model_info', {}).get('total_params', 'N/A')
                })

        # Pre-Fusion
        for layer_dir in experiment_dir.glob("pre_fusion_*layer_cleaned"):
            result_file = layer_dir / "results" / "experiment_result.json"
            if result_file.exists():
                with open(result_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    layers = layer_dir.name.split('_')[2].replace('layer', '')
                    models_found.append({
                        'name': f'Pre-Fusion {layers}L',
                        'accuracy': data['final_metrics']['accuracy'],
                        'f1': data['final_metrics']['macro_f1'],
                        'params': data.get('model_info', {}).get('total_params', 'N/A')
                    })

        # Post-Fusion
        for layer_dir in experiment_dir.glob("post_fusion_*layer_cleaned"):
            result_file = layer_dir / "results" / "experiment_result.json"
            if result_file.exists():
                with open(result_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    layers = layer_dir.name.split('_')[2].replace('layer', '')
                    models_found.append({
                        'name': f'Post-Fusion {layers}L',
                        'accuracy': data['final_metrics']['accuracy'],
                        'f1': data['final_metrics']['macro_f1'],
                        'params': data.get('model_info', {}).get('total_params', 'N/A')
                    })

        if not models_found:
            report_lines.append("  ç„¡æ¨¡å‹çµæœ")
            continue

        # æ’åºä¸¦é¡¯ç¤ºçµæœ
        models_found.sort(key=lambda x: x['f1'], reverse=True)

        report_lines.append("\næ¨¡å‹æ€§èƒ½æ’åï¼ˆä¾ Macro-F1 æ’åºï¼‰")
        report_lines.append("-" * 80)
        report_lines.append(f"{'æ’å':<6} {'æ¨¡å‹':<20} {'Accuracy':<12} {'Macro-F1':<12} {'åƒæ•¸é‡':<15}")
        report_lines.append("-" * 80)

        for i, model in enumerate(models_found, 1):
            rank_marker = "â­" if i == 1 else f"{i}."
            # æ ¼å¼åŒ–åƒæ•¸é‡ï¼ˆè™•ç† N/A æˆ–æ•¸å­—ï¼‰
            params_str = f"{model['params']:,}" if isinstance(model['params'], int) else str(model['params'])
            report_lines.append(
                f"{rank_marker:<6} {model['name']:<20} "
                f"{model['accuracy']:<12.4f} {model['f1']:<12.4f} "
                f"{params_str:<15}"
            )

        report_lines.append("-" * 80)

        # æœ€ä½³æ¨¡å‹
        best = models_found[0]
        best_params_str = f"{best['params']:,}" if isinstance(best['params'], int) else str(best['params'])
        report_lines.append(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼š{best['name']}")
        report_lines.append(f"   - Accuracy: {best['accuracy']:.4f}")
        report_lines.append(f"   - Macro-F1: {best['f1']:.4f}")
        report_lines.append(f"   - åƒæ•¸é‡: {best_params_str}")

    # è¼¸å‡ºä½ç½®
    report_lines.append("\n\n" + "=" * 80)
    report_lines.append("è¼¸å‡ºæª”æ¡ˆä½ç½®")
    report_lines.append("=" * 80)
    report_lines.append(f"\nğŸ“Š æ¯”è¼ƒè¡¨æ ¼: {BASE_DIR / 'outputs' / 'paper_materials' / 'tables' / ''}")
    report_lines.append(f"ğŸ“ˆ é«˜å“è³ªåœ–è¡¨: {BASE_DIR / 'outputs' / 'paper_materials' / 'figures' / ''}")
    report_lines.append(f"ğŸ’¾ æ¨¡å‹æª¢æŸ¥é»: {BASE_DIR / 'outputs' / 'checkpoints' / ''}")
    report_lines.append(f"ğŸ“ å¯¦é©—çµæœ: {base_experiment_dir}")

    report_lines.append("\n" + "=" * 80)
    report_lines.append("[æˆåŠŸ] å®Œæ•´å¯¦é©—æµç¨‹åŸ·è¡Œå®Œç•¢ï¼")
    report_lines.append("=" * 80)

    # å°å‡ºå ±å‘Š
    report_text = "\n".join(report_lines)
    print(report_text)

    # å„²å­˜å ±å‘Š
    report_path = BASE_DIR / "outputs" / "paper_materials" / "experiment_report.txt"
    report_path.parent.mkdir(parents=True, exist_ok=True)
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"\nå ±å‘Šå·²å„²å­˜: {report_path}")

    return True


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description='åŸ·è¡Œå®Œæ•´çš„ ABSA å¯¦é©—æµç¨‹')
    parser.add_argument('--skip-cleaning', action='store_true', help='è·³éè³‡æ–™æ¸…ç†æ­¥é©Ÿ')
    parser.add_argument('--skip-training', action='store_true', help='è·³éæ¨¡å‹è¨“ç·´æ­¥é©Ÿ')
    parser.add_argument('--skip-analysis', action='store_true', help='è·³éåˆ†æèˆ‡è¦–è¦ºåŒ–æ­¥é©Ÿ')
    parser.add_argument('--models', choices=['all', 'baseline', 'prefusion', 'postfusion'],
                       default='all', help='æŒ‡å®šè¦è¨“ç·´çš„æ¨¡å‹')

    args = parser.parse_args()

    print("=" * 80)
    print("å®Œæ•´ ABSA å¯¦é©—æµç¨‹")
    print("=" * 80)
    print("\næµç¨‹èªªæ˜ï¼š")
    print("  1. è³‡æ–™æ¸…ç†èˆ‡é©—è­‰")
    print("  2. æ¨¡å‹è¨“ç·´ï¼ˆBaseline + Pre-Fusion + Post-Fusionï¼‰")
    print("  3. çµæœåˆ†æèˆ‡è¦–è¦ºåŒ–")
    print("  4. ç”¢ç”Ÿå®Œæ•´å¯¦é©—å ±å‘Š")
    print("\né ä¼°ç¸½è€—æ™‚ï¼š3-4 å°æ™‚")

    # ç¢ºèªåŸ·è¡Œ
    response = input("\næ˜¯å¦é–‹å§‹åŸ·è¡Œï¼Ÿ(y/n): ")
    if response.lower() != 'y':
        print("å·²å–æ¶ˆåŸ·è¡Œ")
        return

    start_time = time.time()

    # æ­¥é©Ÿ 1ï¼šè³‡æ–™æ¸…ç†
    if not args.skip_cleaning:
        success = step1_data_cleaning()
        if not success:
            print("\n[éŒ¯èª¤] è³‡æ–™æ¸…ç†éšæ®µå¤±æ•—")
            return
    else:
        print("\n[è·³é] è³‡æ–™æ¸…ç†æ­¥é©Ÿ")

    # æ­¥é©Ÿ 2ï¼šæ¨¡å‹è¨“ç·´
    if not args.skip_training:
        success = step2_train_models(args.models)
        if not success:
            print("\n[éŒ¯èª¤] æ¨¡å‹è¨“ç·´éšæ®µå¤±æ•—")
            return
    else:
        print("\n[è·³é] æ¨¡å‹è¨“ç·´æ­¥é©Ÿ")

    # æ­¥é©Ÿ 3ï¼šåˆ†æèˆ‡è¦–è¦ºåŒ–
    if not args.skip_analysis:
        success = step3_generate_analysis()
        if not success:
            print("\n[éŒ¯èª¤] åˆ†æèˆ‡è¦–è¦ºåŒ–éšæ®µå¤±æ•—")
            return
    else:
        print("\n[è·³é] åˆ†æèˆ‡è¦–è¦ºåŒ–æ­¥é©Ÿ")

    # æ­¥é©Ÿ 4ï¼šç”¢ç”Ÿå ±å‘Š
    success = step4_generate_report()

    # ç¸½çµ
    total_time = time.time() - start_time
    hours = int(total_time // 3600)
    minutes = int((total_time % 3600) // 60)
    seconds = int(total_time % 60)

    print("\n" + "=" * 80)
    print(f"ç¸½åŸ·è¡Œæ™‚é–“: {hours} å°æ™‚ {minutes} åˆ† {seconds} ç§’")
    print("=" * 80)


if __name__ == "__main__":
    main()
