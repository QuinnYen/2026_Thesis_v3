"""
çµ±ä¸€è¨“ç·´è…³æœ¬ - æ”¯æ´å¤šç¶­åº¦å¯¦é©—é…ç½®

æ­¤è…³æœ¬æ•´åˆäº† Baselineã€Pre-Fusionã€Post-Fusion ä¸‰ç¨®æ¨¡å‹çš„è¨“ç·´é‚è¼¯ï¼Œ
æ”¯æ´åœ¨ä¸€æ¬¡é‹è¡Œä¸­å®Œæˆå¤šå€‹ç¶­åº¦çš„å¯¦é©—ï¼š
- å¤šå€‹æ•¸æ“šé›†
- å¤šç¨®æ¨¡å‹é¡å‹
- å¤šç¨®å±¤æ•¸é…ç½®
- å¤šç¨®è»Ÿé®ç½©é…ç½®
- å¤šç¨®è©å‘é‡é…ç½®

ä½¿ç”¨ç¯„ä¾‹ï¼š
    # å–®ä¸€å¯¦é©—
    python scripts/train_unified.py --dataset SemEval2014_Restaurant --model baseline

    # æ‰¹æ¬¡å¯¦é©—
    python scripts/train_unified.py \
        --datasets SemEval2014_Restaurant SemEval2014_Laptop \
        --models baseline prefusion postfusion \
        --layers 2 3 4 5 \
        --soft_mask_configs hard_mask soft_mask_normalized
"""

import sys
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
import json
import time
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
import argparse
from tqdm import tqdm
from itertools import product
from typing import List, Dict, Optional, Tuple

# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘
BASE_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BASE_DIR / "src"))
sys.path.insert(0, str(BASE_DIR / "src" / "models"))
sys.path.insert(0, str(BASE_DIR / "src" / "data_processing"))
sys.path.insert(0, str(BASE_DIR / "configs"))

from models.baseline import BaselineModel
from models.pre_fusion import PreFusionModel
from models.post_fusion import PostFusionModel
from data_processing.cleaned_data_loader import create_cleaned_data_loaders, get_vocab_words
from data_processing.embedding_loader import load_glove_embeddings
from experiment_config import (
    DATASETS, BASELINE_CONFIG, PREFUSION_CONFIG, POSTFUSION_CONFIG,
    SOFT_MASK_EXPERIMENTS, get_output_dir, get_dataset_path
)

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False


class EarlyStopping:
    """Early Stopping æ©Ÿåˆ¶"""

    def __init__(self, patience=5, min_delta=0.001, mode='max'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, score):
        if self.best_score is None:
            self.best_score = score
        elif self.mode == 'max':
            if score < self.best_score + self.min_delta:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True
            else:
                self.best_score = score
                self.counter = 0
        else:
            if score > self.best_score - self.min_delta:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True
            else:
                self.best_score = score
                self.counter = 0

        return self.early_stop


def train_epoch(model, train_loader, criterion, optimizer, device):
    """è¨“ç·´ä¸€å€‹ epoch"""
    model.train()
    total_loss = 0
    all_preds = []
    all_labels = []

    pbar = tqdm(train_loader, desc='è¨“ç·´ä¸­', leave=False, ncols=100)

    for batch in pbar:
        input_ids = batch['input_ids'].to(device)
        aspect_mask = batch['aspect_mask'].to(device)
        labels = batch['label'].to(device)

        optimizer.zero_grad()
        logits, _ = model(input_ids, aspect_mask)
        loss = criterion(logits, labels)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        total_loss += loss.item()
        preds = torch.argmax(logits, dim=1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

        pbar.set_postfix({'loss': f'{loss.item():.4f}'})

    avg_loss = total_loss / len(train_loader)
    acc = accuracy_score(all_labels, all_preds)

    return avg_loss, acc


def evaluate(model, val_loader, criterion, device):
    """è©•ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            aspect_mask = batch['aspect_mask'].to(device)
            labels = batch['label'].to(device)

            logits, _ = model(input_ids, aspect_mask)
            loss = criterion(logits, labels)

            total_loss += loss.item()
            preds = torch.argmax(logits, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    avg_loss = total_loss / len(val_loader)
    acc = accuracy_score(all_labels, all_preds)
    precision, recall, f1, _ = precision_recall_fscore_support(
        all_labels, all_preds, average='macro', zero_division=0
    )

    return avg_loss, acc, precision, recall, f1, all_preds, all_labels


def plot_training_curves(history, output_dir):
    """ç¹ªè£½è¨“ç·´æ›²ç·š"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Loss
    axes[0, 0].plot(history['train_loss'], label='Train Loss')
    axes[0, 0].plot(history['val_loss'], label='Val Loss')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].set_title('è¨“ç·´/é©—è­‰æå¤±æ›²ç·š')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # Accuracy
    axes[0, 1].plot(history['train_acc'], label='Train Acc')
    axes[0, 1].plot(history['val_acc'], label='Val Acc')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Accuracy')
    axes[0, 1].set_title('è¨“ç·´/é©—è­‰æº–ç¢ºç‡æ›²ç·š')
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    # F1 Score
    axes[1, 0].plot(history['val_f1'], label='Val F1', color='green')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('F1 Score')
    axes[1, 0].set_title('é©—è­‰ F1 åˆ†æ•¸æ›²ç·š')
    axes[1, 0].legend()
    axes[1, 0].grid(True)

    # Precision & Recall
    axes[1, 1].plot(history['val_precision'], label='Precision', color='blue')
    axes[1, 1].plot(history['val_recall'], label='Recall', color='orange')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('Score')
    axes[1, 1].set_title('Precision èˆ‡ Recall æ›²ç·š')
    axes[1, 1].legend()
    axes[1, 1].grid(True)

    plt.tight_layout()
    plt.savefig(output_dir / 'training_curves.png', dpi=150, bbox_inches='tight')
    plt.close()


def plot_confusion_matrix(labels, preds, output_dir):
    """ç¹ªè£½æ··æ·†çŸ©é™£"""
    cm = confusion_matrix(labels, preds)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Positive', 'Negative', 'Neutral'],
                yticklabels=['Positive', 'Negative', 'Neutral'])
    plt.title('æ··æ·†çŸ©é™£')
    plt.ylabel('çœŸå¯¦æ¨™ç±¤')
    plt.xlabel('é æ¸¬æ¨™ç±¤')
    plt.tight_layout()
    plt.savefig(output_dir / 'confusion_matrix.png', dpi=150, bbox_inches='tight')
    plt.close()


def create_model(model_type: str, vocab_size: int, config: dict,
                 pretrained_embeddings: Optional[torch.Tensor] = None,
                 num_layers: int = None):
    """
    å»ºç«‹æ¨¡å‹å¯¦ä¾‹

    Args:
        model_type: æ¨¡å‹é¡å‹ ("baseline", "prefusion", "postfusion")
        vocab_size: è©å½™è¡¨å¤§å°
        config: æ¨¡å‹é…ç½®å­—å…¸
        pretrained_embeddings: é è¨“ç·´è©å‘é‡
        num_layers: LSTM å±¤æ•¸ï¼ˆåƒ…ç”¨æ–¼ pre/post-fusionï¼‰

    Returns:
        model: æ¨¡å‹å¯¦ä¾‹
    """
    if model_type == "baseline":
        model = BaselineModel(
            vocab_size=vocab_size,
            embedding_dim=config.get('embedding_dim', 300),
            hidden_size=config.get('hidden_size', 128),
            num_classes=3,
            dropout=config.get('dropout', 0.3),
            pretrained_embeddings=pretrained_embeddings,
            freeze_embeddings=config.get('freeze_embeddings', False),
            use_soft_mask=config.get('use_soft_mask', False),
            penalty_weight=config.get('penalty_weight', 5.0),
            context_window=config.get('context_window', 2),
            normalize_penalty=config.get('normalize_penalty', False)
        )
    elif model_type == "prefusion":
        model = PreFusionModel(
            vocab_size=vocab_size,
            embedding_dim=config.get('embedding_dim', 300),
            hidden_size=config.get('hidden_size', 128),
            num_lstm_layers=num_layers or 2,
            num_classes=3,
            dropout=config.get('dropout', 0.3),
            pretrained_embeddings=pretrained_embeddings,
            freeze_embeddings=config.get('freeze_embeddings', False)
        )
    elif model_type == "postfusion":
        model = PostFusionModel(
            vocab_size=vocab_size,
            embedding_dim=config.get('embedding_dim', 300),
            hidden_size=config.get('hidden_size', 128),
            num_lstm_layers=num_layers or 2,
            num_classes=3,
            dropout=config.get('dropout', 0.3),
            pretrained_embeddings=pretrained_embeddings,
            freeze_embeddings=config.get('freeze_embeddings', False)
        )
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹é¡å‹: {model_type}")

    return model


def train_single_experiment(
    dataset_name: str,
    model_type: str,
    train_loader,
    val_loader,
    vocab,
    class_weights,
    device,
    config: dict,
    num_layers: Optional[int] = None,
    soft_mask_config: Optional[str] = None
):
    """
    è¨“ç·´å–®ä¸€å¯¦é©—é…ç½®

    Args:
        dataset_name: æ•¸æ“šé›†åç¨±
        model_type: æ¨¡å‹é¡å‹
        train_loader: è¨“ç·´è³‡æ–™è¼‰å…¥å™¨
        val_loader: é©—è­‰è³‡æ–™è¼‰å…¥å™¨
        vocab: è©å½™è¡¨
        class_weights: é¡åˆ¥æ¬Šé‡
        device: è¨ˆç®—è£ç½®
        config: é…ç½®å­—å…¸
        num_layers: LSTM å±¤æ•¸ï¼ˆå¯é¸ï¼‰
        soft_mask_config: è»Ÿé®ç½©é…ç½®åç¨±ï¼ˆå¯é¸ï¼‰

    Returns:
        results: å¯¦é©—çµæœå­—å…¸
    """
    # å»ºç«‹å¯¦é©—æ¨™è­˜
    exp_id = f"{model_type}"
    if num_layers is not None:
        exp_id += f"_{num_layers}layer"
    if soft_mask_config is not None:
        exp_id += f"_{soft_mask_config}"

    print("\n" + "=" * 80)
    print(f"è¨“ç·´å¯¦é©—: {dataset_name} - {exp_id}")
    print("=" * 80)

    # å¦‚æœæœ‰è»Ÿé®ç½©é…ç½®ï¼Œåˆä½µåˆ° config ä¸­
    if soft_mask_config and soft_mask_config in SOFT_MASK_EXPERIMENTS:
        config = {**config, **SOFT_MASK_EXPERIMENTS[soft_mask_config]}

    # è¼‰å…¥é è¨“ç·´è©å‘é‡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
    pretrained_embeddings = None
    if config.get('use_pretrained_embeddings', False):
        print("\nè¼‰å…¥ GloVe é è¨“ç·´è©å‘é‡...")
        try:
            glove_dir = BASE_DIR / "data" / "embeddings"
            glove_embedding = load_glove_embeddings(
                embedding_dim=300,
                data_dir=str(glove_dir),
                use_cache=True
            )

            vocab_words = get_vocab_words(vocab)
            embedding_matrix, _ = glove_embedding.get_embedding_matrix(
                vocab=vocab_words,
                oov_strategy=config.get('oov_strategy', 'random'),
                seed=42
            )

            pretrained_embeddings = torch.FloatTensor(embedding_matrix)
            print(f"GloVe è©å‘é‡è¼‰å…¥å®Œæˆï¼å½¢ç‹€: {pretrained_embeddings.shape}")
        except Exception as e:
            print(f"è­¦å‘Šï¼šç„¡æ³•è¼‰å…¥ GloVe è©å‘é‡: {e}")
            print("å°‡ä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–çš„è©å‘é‡")

    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    if model_type == "baseline":
        if soft_mask_config:
            output_dir = BASE_DIR / "outputs" / "experiments" / "aspect_level_v2" / dataset_name / f"baseline_{soft_mask_config}"
        else:
            output_dir = get_output_dir(dataset_name, "baseline")
    else:
        output_dir = get_output_dir(dataset_name, model_type, layers=num_layers)

    output_dir.mkdir(parents=True, exist_ok=True)
    checkpoint_dir = output_dir / "checkpoints"
    checkpoint_dir.mkdir(exist_ok=True)
    results_dir = output_dir / "results"
    results_dir.mkdir(exist_ok=True)

    # å»ºç«‹æ¨¡å‹
    print("\nå»ºç«‹æ¨¡å‹...")
    model = create_model(
        model_type=model_type,
        vocab_size=len(vocab),
        config=config,
        pretrained_embeddings=pretrained_embeddings,
        num_layers=num_layers
    )
    model = model.to(device)

    total_params, trainable_params = model.get_num_params()
    print(f"æ¨¡å‹åƒæ•¸é‡: {total_params:,} (å¯è¨“ç·´: {trainable_params:,})")

    # è¨“ç·´è¨­å®š
    criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))
    optimizer = optim.Adam(model.parameters(), lr=config.get('learning_rate', 1e-3))
    early_stopping = EarlyStopping(patience=5, mode='max')

    # è¨“ç·´å¾ªç’°
    print("\né–‹å§‹è¨“ç·´...")
    history = {
        'train_loss': [],
        'train_acc': [],
        'val_loss': [],
        'val_acc': [],
        'val_precision': [],
        'val_recall': [],
        'val_f1': []
    }

    best_f1 = 0
    best_epoch = 0
    num_epochs = config.get('num_epochs', 30)
    start_time = time.time()

    epoch_pbar = tqdm(range(1, num_epochs + 1), desc=f'{exp_id} è¨“ç·´é€²åº¦', ncols=120)

    for epoch in epoch_pbar:
        # è¨“ç·´
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)

        # è©•ä¼°
        val_loss, val_acc, val_precision, val_recall, val_f1, val_preds, val_labels = evaluate(
            model, val_loader, criterion, device
        )

        # è¨˜éŒ„
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)
        history['val_precision'].append(val_precision)
        history['val_recall'].append(val_recall)
        history['val_f1'].append(val_f1)

        # æ›´æ–°é€²åº¦æ¢
        postfix = {
            'Loss': f'{val_loss:.4f}',
            'Acc': f'{val_acc:.4f}',
            'F1': f'{val_f1:.4f}'
        }

        # å„²å­˜æœ€ä½³æ¨¡å‹
        if val_f1 > best_f1:
            best_f1 = val_f1
            best_epoch = epoch

            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_f1': val_f1,
                'val_acc': val_acc,
                'config': config
            }, checkpoint_dir / 'best_model.pt')

            postfix['Best'] = 'âœ“'

        epoch_pbar.set_postfix(postfix)

        # Early Stopping
        if early_stopping(val_f1):
            print(f"\nEarly stopping æ–¼ epoch {epoch}")
            break

    total_time = time.time() - start_time

    # è¼‰å…¥æœ€ä½³æ¨¡å‹ä¸¦æœ€çµ‚è©•ä¼°
    print("\næœ€çµ‚è©•ä¼°ï¼ˆä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼‰...")
    checkpoint = torch.load(checkpoint_dir / 'best_model.pt')
    model.load_state_dict(checkpoint['model_state_dict'])

    final_loss, final_acc, final_precision, final_recall, final_f1, final_preds, final_labels = evaluate(
        model, val_loader, criterion, device
    )

    print(f"\næœ€çµ‚çµæœ:")
    print(f"  Accuracy:  {final_acc:.4f}")
    print(f"  Precision: {final_precision:.4f}")
    print(f"  Recall:    {final_recall:.4f}")
    print(f"  Macro-F1:  {final_f1:.4f}")

    # å„²å­˜çµæœ
    results = {
        'dataset': dataset_name,
        'model_type': model_type,
        'experiment_id': exp_id,
        'num_layers': num_layers,
        'soft_mask_config': soft_mask_config,
        'best_epoch': best_epoch,
        'best_f1': best_f1,
        'final_metrics': {
            'accuracy': final_acc,
            'precision': final_precision,
            'recall': final_recall,
            'macro_f1': final_f1
        },
        'training_time_seconds': total_time,
        'model_info': {
            'total_params': total_params,
            'trainable_params': trainable_params
        },
        'config': config
    }

    with open(results_dir / 'experiment_result.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    # ç¹ªè£½åœ–è¡¨
    plot_training_curves(history, output_dir)
    plot_confusion_matrix(final_labels, final_preds, output_dir)

    print(f"\nçµæœå·²å„²å­˜è‡³: {output_dir}")

    return results


def main():
    parser = argparse.ArgumentParser(description='çµ±ä¸€è¨“ç·´è…³æœ¬ - æ”¯æ´å¤šç¶­åº¦å¯¦é©—')

    # æ•¸æ“šé›†é…ç½®
    parser.add_argument('--dataset', type=str, default=None,
                       help='å–®ä¸€æ•¸æ“šé›†åç¨±')
    parser.add_argument('--datasets', type=str, nargs='+', default=None,
                       help='å¤šå€‹æ•¸æ“šé›†åç¨±ï¼ˆå„ªå…ˆæ–¼ --datasetï¼‰')

    # æ¨¡å‹é…ç½®
    parser.add_argument('--model', type=str, default=None,
                       choices=['baseline', 'prefusion', 'postfusion'],
                       help='å–®ä¸€æ¨¡å‹é¡å‹')
    parser.add_argument('--models', type=str, nargs='+', default=None,
                       choices=['baseline', 'prefusion', 'postfusion'],
                       help='å¤šå€‹æ¨¡å‹é¡å‹ï¼ˆå„ªå…ˆæ–¼ --modelï¼‰')

    # å±¤æ•¸é…ç½®ï¼ˆç”¨æ–¼ pre/post-fusionï¼‰
    parser.add_argument('--layers', type=int, nargs='+', default=None,
                       help='LSTM å±¤æ•¸åˆ—è¡¨ï¼ˆä¾‹å¦‚ï¼š2 3 4 5ï¼‰')

    # è»Ÿé®ç½©é…ç½®ï¼ˆç”¨æ–¼ baselineï¼‰
    parser.add_argument('--soft_mask_configs', type=str, nargs='+', default=None,
                       help='è»Ÿé®ç½©é…ç½®åç¨±åˆ—è¡¨ï¼ˆä¾‹å¦‚ï¼šhard_mask soft_mask_normalizedï¼‰')

    # å…¶ä»–é…ç½®
    parser.add_argument('--use_config_datasets', action='store_true',
                       help='ä½¿ç”¨ experiment_config.py ä¸­é…ç½®çš„æ•¸æ“šé›†')

    args = parser.parse_args()

    print("=" * 80)
    print("çµ±ä¸€è¨“ç·´è…³æœ¬ - å¤šç¶­åº¦å¯¦é©—è¨“ç·´")
    print("=" * 80)

    # ç¢ºå®šè¦è¨“ç·´çš„æ•¸æ“šé›†
    if args.use_config_datasets:
        datasets = DATASETS
    elif args.datasets:
        datasets = args.datasets
    elif args.dataset:
        datasets = [args.dataset]
    else:
        # é è¨­ä½¿ç”¨é…ç½®æª”æ¡ˆä¸­çš„ç¬¬ä¸€å€‹æ•¸æ“šé›†
        datasets = [DATASETS[0]] if DATASETS else ["SemEval2014_Restaurant"]

    # ç¢ºå®šè¦è¨“ç·´çš„æ¨¡å‹
    if args.models:
        models = args.models
    elif args.model:
        models = [args.model]
    else:
        # é è¨­è¨“ç·´æ‰€æœ‰æ¨¡å‹
        models = ['baseline', 'prefusion', 'postfusion']

    print(f"\nå°‡è¨“ç·´ä»¥ä¸‹é…ç½®ï¼š")
    print(f"  æ•¸æ“šé›† ({len(datasets)}): {datasets}")
    print(f"  æ¨¡å‹é¡å‹ ({len(models)}): {models}")
    if args.layers:
        print(f"  å±¤æ•¸é…ç½®: {args.layers}")
    if args.soft_mask_configs:
        print(f"  è»Ÿé®ç½©é…ç½®: {args.soft_mask_configs}")

    # è¨­å®šéš¨æ©Ÿç¨®å­
    torch.manual_seed(42)
    np.random.seed(42)

    # è¨­å®šè£ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è£ç½®: {device}\n")

    # å„²å­˜æ‰€æœ‰å¯¦é©—çµæœ
    all_results = []

    # éæ­·æ‰€æœ‰æ•¸æ“šé›†
    for dataset_name in datasets:
        print("\n" + "=" * 80)
        print(f"æ•¸æ“šé›†: {dataset_name}")
        print("=" * 80)

        # è¼‰å…¥è³‡æ–™ï¼ˆæ‰€æœ‰æ¨¡å‹å…±ç”¨åŒä¸€ä»½è³‡æ–™ï¼‰
        print("\nè¼‰å…¥è³‡æ–™...")
        csv_path = get_dataset_path(dataset_name, "train")

        train_loader, val_loader, vocab, label_map, class_weights = create_cleaned_data_loaders(
            train_csv=csv_path,
            batch_size=32,
            val_split=0.2,
            max_length=128,
            min_freq=2,
            random_seed=42
        )

        print(f"è¨“ç·´æ¨£æœ¬: {len(train_loader.dataset)}")
        print(f"é©—è­‰æ¨£æœ¬: {len(val_loader.dataset)}")
        print(f"è©å½™é‡: {len(vocab)}")

        # è¨“ç·´æ¯å€‹æ¨¡å‹
        for model_type in models:
            if model_type == 'baseline':
                # Baseline æ¨¡å‹é…ç½®
                config = BASELINE_CONFIG.copy()

                # å¦‚æœæŒ‡å®šäº†è»Ÿé®ç½©é…ç½®ï¼Œè¨“ç·´å¤šå€‹ç‰ˆæœ¬
                if args.soft_mask_configs:
                    for soft_mask_config in args.soft_mask_configs:
                        try:
                            results = train_single_experiment(
                                dataset_name=dataset_name,
                                model_type=model_type,
                                train_loader=train_loader,
                                val_loader=val_loader,
                                vocab=vocab,
                                class_weights=class_weights,
                                device=device,
                                config=config,
                                soft_mask_config=soft_mask_config
                            )
                            all_results.append(results)
                        except Exception as e:
                            print(f"\n[éŒ¯èª¤] å¯¦é©—å¤±æ•—: {dataset_name} - {model_type} - {soft_mask_config}")
                            print(f"éŒ¯èª¤è¨Šæ¯: {str(e)}")
                            continue
                else:
                    # è¨“ç·´å–®ä¸€ baseline é…ç½®
                    try:
                        results = train_single_experiment(
                            dataset_name=dataset_name,
                            model_type=model_type,
                            train_loader=train_loader,
                            val_loader=val_loader,
                            vocab=vocab,
                            class_weights=class_weights,
                            device=device,
                            config=config
                        )
                        all_results.append(results)
                    except Exception as e:
                        print(f"\n[éŒ¯èª¤] å¯¦é©—å¤±æ•—: {dataset_name} - {model_type}")
                        print(f"éŒ¯èª¤è¨Šæ¯: {str(e)}")
                        continue

            elif model_type in ['prefusion', 'postfusion']:
                # Pre/Post-Fusion æ¨¡å‹é…ç½®
                config = PREFUSION_CONFIG.copy() if model_type == 'prefusion' else POSTFUSION_CONFIG.copy()

                # ç¢ºå®šè¦è¨“ç·´çš„å±¤æ•¸
                layers_list = args.layers if args.layers else config.get('layers', [2, 3, 4, 5])

                # è¨“ç·´æ¯å€‹å±¤æ•¸é…ç½®
                for num_layers in layers_list:
                    try:
                        results = train_single_experiment(
                            dataset_name=dataset_name,
                            model_type=model_type,
                            train_loader=train_loader,
                            val_loader=val_loader,
                            vocab=vocab,
                            class_weights=class_weights,
                            device=device,
                            config=config,
                            num_layers=num_layers
                        )
                        all_results.append(results)
                    except Exception as e:
                        print(f"\n[éŒ¯èª¤] å¯¦é©—å¤±æ•—: {dataset_name} - {model_type} - {num_layers}å±¤")
                        print(f"éŒ¯èª¤è¨Šæ¯: {str(e)}")
                        continue

    # è¼¸å‡ºç¸½çµ
    print("\n" + "=" * 80)
    print("æ‰€æœ‰å¯¦é©—å®Œæˆï¼")
    print("=" * 80)

    if all_results:
        print(f"\nç¸½å…±å®Œæˆ {len(all_results)} å€‹å¯¦é©—")
        print("\nå¯¦é©—çµæœæ‘˜è¦ï¼š")
        print("-" * 80)
        print(f"{'æ•¸æ“šé›†':<25} {'å¯¦é©—ID':<30} {'F1':<10} {'Acc':<10}")
        print("-" * 80)

        for result in all_results:
            print(f"{result['dataset']:<25} {result['experiment_id']:<30} "
                  f"{result['final_metrics']['macro_f1']:<10.4f} "
                  f"{result['final_metrics']['accuracy']:<10.4f}")

        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_result = max(all_results, key=lambda x: x['final_metrics']['macro_f1'])
        print("\n" + "=" * 80)
        print("ğŸ† æœ€ä½³å¯¦é©—ï¼š")
        print(f"  æ•¸æ“šé›†: {best_result['dataset']}")
        print(f"  å¯¦é©—ID: {best_result['experiment_id']}")
        print(f"  Macro-F1: {best_result['final_metrics']['macro_f1']:.4f}")
        print(f"  Accuracy: {best_result['final_metrics']['accuracy']:.4f}")
        print("=" * 80)
    else:
        print("\n[è­¦å‘Š] æ²’æœ‰æˆåŠŸå®Œæˆçš„å¯¦é©—")


if __name__ == "__main__":
    main()
